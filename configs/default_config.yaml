model:
  name: "meta-llama/Llama-3.2-1B"  # Free, small Llama model
  max_length: 100
  temperature: 0.7
  device: "cuda"  # or "cpu"
  load_in_8bit: false  # Set to true for memory efficiency

defenses:
  enabled: true
  input_sanitization: true
  output_filtering: true
  poison_detection: true
  max_prompt_length: 2000

evaluation:
  num_test_prompts: 50
  save_results: true
  output_dir: "results"
  benchmark_datasets:
    - "adversarial_prompts"
    - "jailbreak_attempts"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"